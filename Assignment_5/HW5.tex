\title{CS 615 - Deep Learning}
\author{
        Assignment 5 -MLPs\\
Winter 2022
}
\date{}
\documentclass[12pt]{article}
\usepackage[margin=0.7in]{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage{comment}
\usepackage{amsmath}
\usepackage{multirow}  %% To have multirows in table
\includecomment{versionB}
%\excludecomment{versionB}

\begin{document}
\maketitle


\section*{Introduction}
In this assignment we will explore the design and use of multi-layer perceptrons for multi-class classification.\\

\section*{Programming Language/Environment}
As per the syllabus, you may work in either Matlab or Python 3.x.  If you are working in Python you must constrain yourself to using numpy, matplotlib, pillow and opencv-python add-on libraries.

\section*{Allowable Libraries/Functions}
In addition, you \textbf{cannot} use any ML functions to do the training or evaluation for you.  Using basic statistical and linear algebra function like \emph{mean}, \emph{std}, \emph{cov} etc.. is fine, but using ones like \emph{train}, \emph{confusion}, etc.. is not. Using any ML-related functions, may result in a \textbf{zero} for the programming component.  In general, use the ``spirit of the assignment'' (where we're implementing things from scratch) as your guide, but if you want clarification on if can use a particular function, DM the professor on slack.


\section*{Grading}
\begin{table}[h]
\begin{center}
\begin{tabular}{|ll|l|}
\hline
Part 1 &Theory &10pts\\
Part 2 &Multi-Class Logistic Regression & 30pts\\
Part 3 &ANN & 30pts\\
Part 4 &Multi-Layer MLP & 30pts\\
\hline
Extra-Credit & Reducing Overfitting & 10pts\\

\hline
\end{tabular}
\caption{Grading Rubric}
\end{center}
\end{table}

\newpage
\section*{Datasets}
\paragraph{MNIST Database } 
The MNIST Database is a dataset of hand-written digits from 0 to 9.  The \emph{original} dataset  contains 60,000 training samples, and 10,000 testing samples, each of which is a $28\times28$ image.\\

\noindent
To keep processing time reasonable, we have extracted 100 observations of each class from the training datase,t and 10 observations of each class from the validation/testing set to create a new dataset in the files \emph{mnist\_train\_100.csv} and \emph{mnist\_valid\_10.csv}, respectively.\\

\noindent
The files are arranged so that each row pertains to an observation, and in each row, the first column is the \emph{target class} $\in \{0,9\}$.  The remaining 784 columns are the \emph{features} of that observation, in this case, the pixel values.  \\

\noindent
For more information about the original dataset, you can visit:  http://yann.lecun.com/exdb/mnist/


\newpage
\section{Theory}
\begin{enumerate}
\item (10pts) In class and the lecture notes, we provided the gradient of the \emph{tanh} function without actually walking through the derivation.  For this assignment's only theory question, show the work on how the partial derivative of the tanh function, $g(z) = \frac{e^z-e^{-z}}{e^z+e^{-z}}$, is $\frac{\partial g(z)}{\partial z} = (1-g^2(z))$

\end{enumerate}
\newpage
\section{Multi-Class Logistic Regression}
In the previous assignment we used a cross-entropy loss function when doing multi-class classification.  Just to mix it up, let's see what happens if we use a sigmoid activation function and log-loss objective function to do multi-class classification.  Your existing implementation should work ``out-of-the-box'' to do this, although you will have to \emph{one-hot-encode} your targets.\\

\noindent
Given the following architecture, perform gradient descent to learn the weights.  Hyperparameter decisions are up to you, although they should be described in your report.  In addition, your report should include a plot showing the value of the objective function for the training and validation datasets as a function of the epoch, and the final training and validation accuracies.\\

\noindent
The architecture is:
$$\text{Input} \rightarrow \text{Fully-Connected} \rightarrow \text{Sigmoid Activation} \rightarrow \text{Log Loss Objective}$$

\section{Artificial Neural Networks}
Next let's add in an additional fully-connected and activation function (which we'll refer to as a \emph{hidden layer} moving forward) so that we have an \emph{artificial neural network}.\\

\noindent
Now it's up to you to make some design decisions!  
\begin{itemize}
\item How many outputs for the first hidden layer?
\item What activation functions to use?
\item What objective function to use?
\item Other decisions related to learning rate, termination, overfitting, etc..
\end{itemize}

\noindent
Try at least three different designs, and in your report provide these design decisions and the resulting training and validation accuracies for each.\\

\begin{centering}
\emph{HINT}: You may want to play with the learning rate and/or incorperate ADAM optimization to avoid things like local minima, exploding or vanishing gradients, saddle points, etc...
\end{centering}

\newpage
\section{Multi-Layer Perceptron}
Now let's allow for multiple hidden layers!\\

\noindent
Try at least three architectures, each of which have at least two hidden layers (and at least one that has more than two).\\

\noindent
In your report, in addition to any hyperparmameter choices,  provide a \emph{table} reporting the training and validation accuracies vs the architecture.

\begin{table}[h]
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
Architecture & Training Accuracy & Validation Accuracy\\
\hline
\hline
TODO & TODO & TODO\\
\hline
\end{tabular}
\caption{Comparison of accuracies for different MLP architectures}
\end{center}
\end{table}

\section{Extra Credit: Reducing Overfitting}
You may have noticed, that with increased model complexity, so came increased overfitting.  To help overcome this, use one of the techniques discussed in class (and in the \emph{Improving Learning} slides) to attempt to reduce overfitting.\\

\noindent
In your report provide:
\begin{itemize}
\item A description of your technique to reduce overfitting.
\item Plot of training and valdiation objective evaluation vs epoch before and after attempting to reduce overfitting.
\item Final training and validation accuracies before and after attempting to reduce overfitting.
\end{itemize}
\newpage
\section*{Submission}
For your submission, upload to Blackboard a single zip file containing:

\begin{enumerate}
\item PDF Writeup
\item Source Code
\item readme.txt file
\end{enumerate}

\noindent
The readme.txt file should contain information on how to run your code to reproduce results for each part of the assignment.\\

\noindent
The PDF document should contain the following:

\begin{enumerate}
\item Part 1:
	\begin{enumerate}
	\item Answer to the theory question.
	\end{enumerate}
\item Part 2:
	\begin{enumerate}
	\item Any hyperparameter choices.
	\item Your plot of the objective function for the training and validation sets as a function of the training epoch.
	\item Your final training and validation accuracies.
	\end{enumerate}
\item Part 3:
	\begin{enumerate}
	\item A list/table of your design choices and resulting training and testing accuracies.
	\end{enumerate}
\item Part 4:
	\begin{enumerate}
	\item Any hyperparameter choices.
	\item Table of training and validation accuracies for different MLP architectures.
	\end{enumerate}
\item Extra Credit:
	\begin{enumerate}
	\item Description of your technique to reduce overfitting.
	\item Plot of training and validation evalution vs training epoch \textbf{before} reducing overfitting.
	\item Plot of training and validation evalution vs training epoch \textbf{after} reducing overfitting.
	\item Final training and validation accuracies before and after reducing overfitting.
	\end{enumerate}
\end{enumerate}
\end{document}

